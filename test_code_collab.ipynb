{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "test_code_collab.ipynb",
      "provenance": [],
      "mount_file_id": "1Dca51KPRQMR2Tl5yVX0HhmlqjP7qXGFo",
      "authorship_tag": "ABX9TyPGTA7M6EyqeeHOoP76YE6f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adeledouin/Collab/blob/main/test_code_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXOZNBfErXOd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdHtfFdSEfm_"
      },
      "source": [
        "# Collab config TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCGB5laCBs_l",
        "outputId": "8a70cec0-7658-451f-93c7-7c44571e43c2"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n",
            "Requirement already satisfied: torch-xla==1.9 from https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl in /usr/local/lib/python3.7/dist-packages (1.9)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.31.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.0.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (20.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3avUqS-EjD9"
      },
      "source": [
        "# Import Projet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOxM9wCTjXau"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import torch "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkN-nnBOEnGJ"
      },
      "source": [
        "py_file_location = \"drive/MyDrive/knit_quakes_forecast/knit_005/\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "\n",
        "\n",
        "from classConfig import ConfigData, ConfigPred\n",
        "import Config_data\n",
        "import Config_pred\n",
        "from classPlot import ClassPlot\n",
        "from Datas.classStat import Histo, Stat\n",
        "from Datas.classSignal import SignalForce, VariationsScalar\n",
        "from Datas.classEvent import ForceEvent\n",
        "# from sub_train_val_test import train_model, test_model\n",
        "from Datas.classData import find_nbseq, CreateDataScalar\n",
        "from Datas.classLoader import DataSetTIMESCALAR, DataSetFalseData\n",
        "from Datas.sub_createdata import create_sequences_field, \\\n",
        "    create_generator_field, create_generator_false_data\n",
        "from Datas.classDataParallel import DataParallel\n",
        "from sub_train_val_test import train_model, test_model\n",
        "from Models.classLoss import MultiGPULossCompute, SimpleLossCompute\n",
        "from Models.classModel import def_nn_models"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCvVTyUBE3c0"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG7KMiRRlrMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f452747-cc25-4243-ca8c-a44b56c8e453"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import warnings\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        "from os import listdir\n",
        "\n",
        "# # PyTorch/XLA GPU Setup (only if GPU runtime)\n",
        "# if os.environ.get('COLAB_GPU', '0') == '1':\n",
        "#   os.environ['GPU_NUM_DEVICES'] = '1'\n",
        "#   os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda/'\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.utils as xu\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.9\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2b3JS5mE6EA"
      },
      "source": [
        "\n",
        "# %% ################### Args ##################################\n",
        "remote = False\n",
        "\n",
        "date = '210617'\n",
        "ref_tricot = 'knit005_'\n",
        "n_exp = 'mix_'\n",
        "version_data = 'v2'\n",
        "version_pred = 'v3'\n",
        "sub_version = ''\n",
        "model = 19\n",
        "\n",
        "train = True\n",
        "checkpoint = ''\n",
        "\n",
        "transfert = False\n",
        "transfert_date = '210616'\n",
        "transfert_pred = ''\n",
        "transfert_sub_version = ''\n",
        "transfert_trainsize = 100000\n",
        "\n",
        "epochs = 5\n",
        "trainsize = 1000000\n",
        "cuda_device = ''\n",
        "num_worker = 4\n",
        "num_cores = 8 if os.environ.get('TPU_NAME', None) else 1\n",
        "log_step = 20\n",
        "metrics_debug = False\n",
        "\n",
        "\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.remote = remote\n",
        "        self.cuda = False\n",
        "        self.vpred = version_pred\n",
        "        self.subv = sub_version\n",
        "        self.pred = 'scalar'\n",
        "        self.train = train\n",
        "        self.verif_stats_output = False\n",
        "        self.checkpoint = checkpoint\n",
        "        self.epoch = epochs\n",
        "        self.trainsize = trainsize\n",
        "        self.cuda_device = cuda_device\n",
        "        self.transfert = transfert\n",
        "        self.transfert_date = transfert_date\n",
        "        self.transfert_pred = transfert_pred\n",
        "        self.transfert_sub_version = transfert_sub_version\n",
        "        self.transfert_trainsize = transfert_trainsize\n",
        "        self.num_workers = num_worker\n",
        "        self.num_cores = num_cores\n",
        "        self.log_step = log_step\n",
        "        self.metric_debug = metrics_debug\n",
        "\n",
        "args = Args()\n",
        "\n",
        "if args.cuda:\n",
        "    if type(args.cuda_device).__name__ == 'str':\n",
        "        device = torch.device(args.cuda_device)\n",
        "    else:\n",
        "        device = args.cuda_device\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "NAME_EXP = ref_tricot + n_exp + version_data\n",
        "config_data = ConfigData(Config_data.exp[NAME_EXP])\n",
        "\n",
        "NAME_EXP = ref_tricot + version_pred\n",
        "if args.pred == 'scalar':\n",
        "    version_exp = Config_pred.exp_scalar[NAME_EXP]\n",
        "    config_pred = ConfigPred(Config_pred.exp_scalar[NAME_EXP], config_data)\n",
        "else:\n",
        "    version_exp = Config_pred.exp_img[NAME_EXP]\n",
        "    config_pred = ConfigPred(Config_pred.exp_img[NAME_EXP], config_data)\n",
        "\n",
        "config_pred.set_model_attribute(model)\n",
        "if args.pred == 'scalar':\n",
        "    model_spec = config_pred.spec_model_scalar()\n",
        "else:\n",
        "    model_spec = config_pred.spec_model_img()\n",
        "\n",
        "histo = Histo(config_data)\n",
        "plot = ClassPlot(args.remote, histo)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKW2tEHwodmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23362022-d2c2-457c-a655-18508ed06ebc"
      },
      "source": [
        "print(config_pred.global_path_load)\n",
        "\n",
        "print(config_pred.global_path_save)\n",
        "\n",
        "# os.chdir(\"/content/drive/MyDrive/knit_quakes_forecast/knit_005/input/version2/flu_rsc_NN\")\n",
        "# !ls\n",
        "\n",
        "a = np.load('/content/drive/MyDrive/knit_quakes_forecast/knit_005/input/version2/' + 'flu_rsc_NN/flu_rsc_train.npy')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/knit_quakes_forecast/knit_005/input/version2/\n",
            "/content/drive/MyDrive/knit_quakes_forecast/knit_005/output/version2/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt01d0z1oZKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac9158a-b321-4cab-9c91-789aaa540e6d"
      },
      "source": [
        "\n",
        "# %% ################### Create sequences ##################################\n",
        "\n",
        "print('------ create data sequences ------')\n",
        "signal_flu = [SignalForce(config_data, 'flu_rsc', NN) for NN in config_pred.NN_data]\n",
        "signalevent = [ForceEvent(config_data, signal_flu[i].f, signal_flu[i].ext, signal_flu[i].t,\n",
        "                          'flu_rsc', config_pred.NN_data[i], Sm=False) for i in\n",
        "               range(np.size(config_pred.NN_data))]\n",
        "\n",
        "nb_seq = [\n",
        "    find_nbseq(config_pred, signal_flu[0], config_pred.seq_size, config_pred.futur, config_pred.overlap_step,\n",
        "               trainsize) if trainsize is None else trainsize,\n",
        "    find_nbseq(config_pred, signal_flu[1], config_pred.seq_size, config_pred.futur, config_pred.overlap_step,\n",
        "               trainsize),\n",
        "    find_nbseq(config_pred, signal_flu[2], config_pred.seq_size, config_pred.futur, config_pred.overlap_step,\n",
        "               trainsize)]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ create data sequences ------\n",
            "/content/drive/MyDrive/knit_quakes_forecast/knit_005/input/version2/flu_rsc_NN/\n",
            "/content/drive/MyDrive/knit_quakes_forecast/knit_005/input/version2/flu_rsc_NN/\n",
            "/content/drive/MyDrive/knit_quakes_forecast/knit_005/input/version2/flu_rsc_NN/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfEj6n8OkThX"
      },
      "source": [
        "def train_model(args, device, nb_seq):\n",
        "    torch.manual_seed(1)\n",
        "\n",
        "    def get_dataset():\n",
        "        # print('avant train nb seq = {}'.format(nb_seq))\n",
        "        train_dataset = DataSetTIMESCALAR(config_data, config_pred, remote, plot, histo, nb_seq.copy(), signal_flu,\n",
        "                                          signalevent, 0)\n",
        "        # print('avant val nb seq = {}'.format(nb_seq))\n",
        "        val_dataset = DataSetTIMESCALAR(config_data, config_pred, remote, plot, histo, nb_seq.copy(), signal_flu,\n",
        "                                        signalevent,\n",
        "                                        1)\n",
        "        # print('avant test nb seq = {}'.format(nb_seq))\n",
        "        test_dataset = DataSetTIMESCALAR(config_data, config_pred, remote, plot, histo, nb_seq.copy(), signal_flu,\n",
        "                                         signalevent,\n",
        "                                         2)\n",
        "\n",
        "        return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "    SERIAL_EXEC = xmp.MpSerialExecutor()\n",
        "    # Using the serial executor avoids multiple processes\n",
        "    # to download the same data.\n",
        "    train_dataset, val_dataset, test_dataset = SERIAL_EXEC.run(get_dataset)\n",
        "\n",
        "\n",
        "    if config_pred.output_type == 'class':\n",
        "        if not config_pred.equipro:\n",
        "            config_pred.set_weight_classes(1 / train_dataset.prop)\n",
        "            print(train_dataset.prop, 1 / train_dataset.prop)\n",
        "    nb_seq = train_dataset.nb_seq.copy()\n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        train_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config_pred.batch_size,\n",
        "        sampler=train_sampler,\n",
        "        num_workers=args.num_workers,\n",
        "        drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=config_pred.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.num_workers,\n",
        "        drop_last=True)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config_pred.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.num_workers,\n",
        "        drop_last=True)\n",
        "\n",
        "    # %% ################### Informations ##################################\n",
        "\n",
        "    if args.pred == 'scalar':\n",
        "        num_test = ('{}_{}_m{}_{}seq{}').format(date, version_pred, model_spec['magic_number'], nb_seq[0], sub_version)\n",
        "    else:\n",
        "        num_test = ('{}_{}_m{}_{}seq{}').format(date, version_pred, model_spec['magic_number'], nb_seq[0], sub_version)\n",
        "\n",
        "    save_best_acc = config_pred.global_path_save + 'net/{}/best_acc_{}.tar'.format(args.pred, num_test)\n",
        "    save_best_loss = config_pred.global_path_save + 'net/{}/best_loss_{}.tar'.format(args.pred, num_test)\n",
        "    save_dict_version = config_pred.global_path_save + 'net/{}/config_pred_{}'.format(args.pred, num_test)\n",
        "    save_dict_model = config_pred.global_path_save + 'net/{}/model_{}'.format(args.pred, num_test)\n",
        "\n",
        "    print('------ {} on model {} ------'.format(NAME_EXP, model_spec['magic_number']))\n",
        "    print('run on cuda : {} ; cuda device : {}'.format(args.cuda, device))\n",
        "    if args.train:\n",
        "        print('on va train {} on {} epochs with training size {}'.format(model_spec['model_name'], args.epoch, nb_seq[0]))\n",
        "    else:\n",
        "        print('on va test {}'.format(model_spec['model_name']))\n",
        "    print('pred with {} past on futur window of {}'.format(config_pred.seq_size, config_pred.futur))\n",
        "    print('avec {} seqs dans val, {} seqs dans test'.format(nb_seq[1], nb_seq[2]))\n",
        "\n",
        "\n",
        "    # %% ################### NN model ##################################\n",
        "\n",
        "    print('------ create model ------')\n",
        "    np.save(save_dict_version, version_exp)\n",
        "    np.save(save_dict_model, model_spec)\n",
        "\n",
        "\n",
        "    if args.pred == 'scalar':\n",
        "        def_nn = def_nn_models(args, device, model_spec['model_name'], config_pred.output_type,\n",
        "                               model_spec['layers_param'], model_spec['opti_param'], model_spec['criterion_param'],\n",
        "                               config_pred.batch_size, config_pred.seq_size, config_pred.channel, None, None,\n",
        "                               config_pred.output_shape)\n",
        "    else:\n",
        "        def_nn = def_nn_models(args, device, model_spec['model_name'], config_pred.output_type,\n",
        "                               model_spec['layers_param'], model_spec['opti_param'], model_spec['criterion_param'],\n",
        "                               config_pred.batch_size, config_pred.seq_size, config_pred.channel, sw, sc,\n",
        "                               config_pred.output_shape)\n",
        "\n",
        "    model, optimizer, scheduler, loss_criterion = def_nn.NN_model()\n",
        "\n",
        "    model, optimizer = def_nn.recup_from_checkpoint(config_pred, args, model_spec, model, optimizer, num_test, save_best_acc, save_best_loss)\n",
        "\n",
        "    if type(args.cuda_device).__name__ == 'list':\n",
        "        model = DataParallel(model, device_ids=device)\n",
        "\n",
        "    # Only instantiate model weights once in memory.\n",
        "    WRAPPED_MODEL = xmp.MpModelWrapper(model)\n",
        "\n",
        "    # Scale learning rate to num cores\n",
        "    learning_rate = model_spec['opti_param']['lr'] * xm.xrt_world_size()\n",
        "\n",
        "    # Get loss function, optimizer, and model\n",
        "    device = xm.xla_device()\n",
        "    model = WRAPPED_MODEL.to(device)\n",
        "\n",
        "\n",
        "    # %% ################### Training ##################################\n",
        "    # Train and eval loops\n",
        "    from Train_loop_collab import train_loop_fn, test_loop_fn\n",
        "\n",
        "    accuracy = 0.0\n",
        "    data, pred, target = None, None, None\n",
        "    for epoch in range(1, args.epoch + 1):\n",
        "        para_loader = pl.ParallelLoader(train_loader, [device])\n",
        "        train_loop_fn(args, config_pred, para_loader.per_device_loader(device), model, optimizer, loss_criterion)\n",
        "        xm.master_print(\"Finished training epoch {}\".format(epoch))\n",
        "\n",
        "        para_loader = pl.ParallelLoader(test_loader, [device])\n",
        "        accuracy, data, pred, target = test_loop_fn(para_loader.per_device_loader(device), model)\n",
        "        if args.metrics_debug:\n",
        "            xm.master_print(met.metrics_report(), flush=True)\n",
        "\n",
        "    return accuracy, data, pred, target\n",
        "\n",
        "# Start training processes\n",
        "def _mp_fn(rank, args, device, nb_seq):\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  accuracy, data, pred, target = train_model(args, device, nb_seq)\n",
        "  if rank == 0:\n",
        "    # Retrieve tensors that are on TPU core 0 and plot.\n",
        "\n",
        "    # %% ################### plot callback ##################################\n",
        "\n",
        "    save_metric = config_pred.global_path_save + 'callback/{}/metric'.format(args.pred)\n",
        "\n",
        "    y_target = target.cpu()\n",
        "\n",
        "    y_pred = pred.cpu()\n",
        "\n",
        "\n",
        "    def classes_scores(config_pred, y_target, repport=False):\n",
        "        target = np.zeros((np.size(y_target), config_pred.output_shape))\n",
        "        pred = np.zeros((np.size(y_target), config_pred.output_shape))\n",
        "\n",
        "        for i in range(np.size(y_target)):\n",
        "            target[i, int(y_target[i])] = 1\n",
        "            pred[i, int(y_pred[i])] = 1\n",
        "\n",
        "        print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_target, y_pred)))\n",
        "\n",
        "        print('Micro Precision: {:.2f}'.format(precision_score(y_target, y_pred, average='micro')))\n",
        "        print('Micro Recall: {:.2f}'.format(recall_score(y_target, y_pred, average='micro')))\n",
        "        print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_target, y_pred, average='micro')))\n",
        "\n",
        "        print('Macro Precision: {:.2f}'.format(precision_score(y_target, y_pred, average='macro')))\n",
        "        print('Macro Recall: {:.2f}'.format(recall_score(y_target, y_pred, average='macro')))\n",
        "        print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_target, y_pred, average='macro')))\n",
        "\n",
        "        print('Weighted Precision: {:.2f}'.format(precision_score(y_target, y_pred, average='weighted')))\n",
        "        print('Weighted Recall: {:.2f}'.format(recall_score(y_target, y_pred, average='weighted')))\n",
        "        print('Weighted F1-score: {:.2f}'.format(f1_score(y_target, y_pred, average='weighted')))\n",
        "\n",
        "        if repport:\n",
        "            print('\\nClassification Report\\n')\n",
        "            print(classification_report(y_target, y_pred,\n",
        "                                        target_names=['Class {}'.format(i) for i in range(config_pred.output_shape)]))\n",
        "\n",
        "\n",
        "    def make_grid_classes(classes_edges):\n",
        "        grid = np.zeros(np.size(classes_edges))\n",
        "        for i in range(np.size(classes_edges)):\n",
        "            grid[i] = classes_edges[i]\n",
        "        return grid\n",
        "\n",
        "\n",
        "    def accuracy_value_dispach(y_value, y_target, y_pred):\n",
        "        g_value = []\n",
        "        w_value = []\n",
        "\n",
        "        for i in range(np.size(y_value)):\n",
        "            if y_pred[i] == y_target[i]:\n",
        "                g_value.append(y_value[i])\n",
        "            else:\n",
        "                w_value.append(y_value[i])\n",
        "\n",
        "        return np.asarray(g_value), np.asarray(w_value)\n",
        "\n",
        "\n",
        "    if config_pred.output_type == 'class':\n",
        "        from Datas.classStat import Stat\n",
        "\n",
        "        nbclasses = config_pred.output_shape\n",
        "        print('#-------------classes--------------#')\n",
        "\n",
        "        classes_scores(config_pred, y_target, y_pred, repport=True)\n",
        "\n",
        "        conf = np.asarray(confusion_matrix(y_target, y_pred))\n",
        "\n",
        "        X_conf = np.arange(nbclasses)\n",
        "        yname = 'quantit√© pred'\n",
        "        ysave = 'qt_pred'\n",
        "        fig, ax = plot.belleFigure('${}$'.format('classe'), '${}$'.format(yname), nfigure=None)\n",
        "        norm = np.asarray([np.sum(conf[:, i]) for i in range(nbclasses)])\n",
        "        for i in range(nbclasses):\n",
        "            ax.plot(X_conf, (conf[i, :] / norm) * 100, '.', label='classe {}'.format(i))\n",
        "        # plot.plt.xscale('log')\n",
        "        # plot.plt.yscale('log')\n",
        "        save = save_metric + '_qt_pred'\n",
        "        plot.fioritures(ax, fig, title='{}'.format(ysave), label=True, grid=None, save=save)\n",
        "\n",
        "        # print('\\nClassification Report\\n')\n",
        "        # print(classification_report(y_target, y_pred,\n",
        "        #                             target_names=['Class {}'.format(i) for i in range(config_pred.output_shape)]))\n",
        "\n",
        "\n",
        "        conf_norm = np.zeros_like(conf, dtype=float)\n",
        "        for i in range(nbclasses):\n",
        "            conf_norm[i, :] = (conf[i, :] / norm) * 100\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "        MAE = np.mean(np.abs(y_target - y_pred))\n",
        "        MSE = np.mean((y_target - y_pred) ** 2)\n",
        "        M4E = np.mean((y_target - y_pred) ** 4)\n",
        "        M6E = np.mean((y_target - y_pred) ** 6)\n",
        "\n",
        "        print(\n",
        "            '\\tMAE: {:.6f} |\\tMSE: {:.6f} |\\tM4E: {:.6f} |\\tM6E: {:.6f}'.format(\n",
        "                MAE, MSE, M4E, M6E))\n",
        "\n",
        "        fig, ax = plot.belleFigure('${}$'.format('pts'), '${}$'.format('y'), nfigure=None)\n",
        "        ax.plot(np.arange(y_target.size), y_target, 'b.', label='target')\n",
        "        ax.plot(np.arange(y_pred.size), y_pred, 'r.', label='pred')\n",
        "        save = save_metric + '_y_time_plot'\n",
        "        plot.fioritures(ax, fig, title=None, label=True, grid=None, save=save)\n",
        "\n",
        "        fig, ax = plot.belleFigure('${}$'.format('y_{target}'), '${}$'.format('y_{pred}'), nfigure=None)\n",
        "        ax.plot(y_target, y_pred, '.', label='')\n",
        "        save = save_metric + '_y_target_vs_pred'\n",
        "        plot.fioritures(ax, fig, title=None, label=None, grid=None, save=save)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juZ5BweCkRlU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "outputId": "b1f7bcaa-7b0a-43d5-e2a6-4a2985b993a1"
      },
      "source": [
        "xmp.spawn(_mp_fn, args=(args, device,nb_seq, ), nprocs=args.num_cores,\n",
        "          start_method='fork')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.348 0.326 0.326] [2.87356322 3.06748466 3.06748466]\n",
            "------ knit005_v3 on model 5019 ------\n",
            "run on cuda : False ; cuda device : cpu\n",
            "on va train ResNet on 5 epochs with training size 1000000\n",
            "pred with 256 past on futur window of 20\n",
            "avec 200000 seqs dans val, 200000 seqs dans test\n",
            "------ create model ------\n",
            "ResNet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in device=TPU:0: 'module' object is not callable\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"<ipython-input-8-e973019b9768>\", line 134, in _mp_fn\n",
            "    accuracy, data, pred, target = train_model(args, device, nb_seq)\n",
            "  File \"<ipython-input-8-e973019b9768>\", line 95, in train_model\n",
            "    model, optimizer, scheduler, loss_criterion = def_nn.NN_model()\n",
            "  File \"/content/drive/MyDrive/knit_quakes_forecast/knit_005/Models/classModel.py\", line 216, in NN_model\n",
            "    criterion = criterion_cross_entropy_loss(torch(self.criterion_param['weight']))\n",
            "TypeError: 'module' object is not callable\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ProcessExitedException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8f45b5f1b7fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m xmp.spawn(_mp_fn, args=(args, device,nb_seq, ), nprocs=args.num_cores,\n\u001b[0;32m----> 2\u001b[0;31m           start_method='fork')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0merror_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0merror_pid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfailed_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                     \u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m                 )\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with exit code 17"
          ]
        }
      ]
    }
  ]
}